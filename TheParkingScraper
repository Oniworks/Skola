from bs4 import BeautifulSoup
from selenium import webdriver
import time
from selenium.webdriver.firefox.service import Service as FirefoxService
from webdriver_manager.firefox import GeckoDriverManager
from selenium import webdriver
from selenium.webdriver.common.by import By
#Starts programm by asking the userfor the parameters of the search
modifier = input("Input the type of car you want to look for or model year: ")
site = ("https://www.theparking.eu/used-cars/{}.html").format(modifier)
pages = input("Number of pages you want to scrape: ")
p = int(pages)
#Initiates Firefox and starts the search
firefox_options = webdriver.FirefoxOptions()
service = FirefoxService(executable_path=GeckoDriverManager().install())
driver = webdriver.Firefox(service=service, options=firefox_options)
driver.get(site)
time.sleep(10)
#Switches view to the cookies pop-up to click on "Decline" for futher access of the site and then switches back to parent window
driver.switch_to.frame("fast-cmp-iframe")
button_decline = driver.find_element(By.CLASS_NAME, "fast-cmp-home-refuse")
button_decline.click()
driver.switch_to.parent_frame()
time.sleep(1)
#Initiates data collection, creates the list and starts the loop
d = 0
data = []
while d < p:
    time.sleep(1)
#Collects data from each page
    page_source = driver.page_source
    soup = BeautifulSoup(page_source, "html.parser")
#Finds and collects the exact values needed
    makes = soup.find_all("span", class_="title-block brand three-dots")
    models = soup.find_all("span", class_="sub-title title-block three-dots")
    prices = soup.find_all("p", class_="prix")
    links = soup.find_all("a", class_="external btn-plus no-partenaire-btn", href=True)
#Goes trough the values and adds them to the list
    i = 0
    j = 0
    k = 0
    g = 0
    while i < len(makes) and j < len(models) and k < len(prices):
        make = makes[i].text
        model = models[j].text
        price = prices[k].text.strip("\n").strip("  ")
        linky = links[g].get("href")
        link = ("https://www.theparking.eu" + linky).strip("\n").strip("  ")
        data.append((make, model, price, link))
        i += 2
        j += 4
        k += 3
        g += 1
#Finds the button to go to the next page and clicks it, starts the loop for the next page as requested by the user
    button_next = driver.find_element(By.CLASS_NAME, "btn-next")
    time.sleep(1)
    button_next.click()
    d += 1
#Shuts down Firefox
driver.quit()
#Prints out all the data
for car in data:
    print(car)
#Finds the price of the cheapest car
cheapest = float('inf') #Honestly don't know what this does
for cheap in data:
#Strips the value of unwanted elements
    price_str = cheap[2].replace(",", "").replace("€", "")
    price_float = float(price_str)
#Compares the values to find the smallest(cheapest) one
    if price_float < cheapest:
        cheapest = price_float
#Prints out all the data for the cheapest car
for i in data:
    comp = int(i[2].replace(",", "").replace("€", ""))
    if comp == cheapest:
        print(i)
